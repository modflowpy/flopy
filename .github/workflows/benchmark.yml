name: FloPy benchmarks

on:
  schedule:
    - cron: '0 8 * * *' # run at 8 AM UTC (12 am PST)

jobs:
  benchmark:
    name: Benchmarks
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ ubuntu-latest, macos-latest, windows-latest ]
        python-version: [ 3.9, "3.10", "3.11", "3.12" ]
    defaults:
      run:
        shell: bash -l {0}
    timeout-minutes: 90

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup uv
        uses: astral-sh/setup-uv@v5
        with:
          version: "0.5.18"

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version-file: pyproject.toml

      - name: Install FloPy
        run: uv sync --all-extras

      - name: Install Modflow executables
        uses: modflowpy/install-modflow-action@v1

      - name: Install triangle (macOS workaround)
        if: runner.os == 'macOS'
        uses: modflowpy/install-modflow-action@v1
        with:
          repo: executables
          ostag: mac
          subset: triangle

      - name: Run benchmarks
        working-directory: autotest
        run: |
          mkdir -p .benchmarks
          uv run pytest -v --durations=0 --benchmark-only --benchmark-json .benchmarks/${{ matrix.os }}_python${{ matrix.python-version }}.json --keep-failed=.failed
          ls .benchmarks
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Upload failed benchmark artifact
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: failed-benchmark-${{ matrix.os }}-${{ matrix.python-version }}-${{ github.run_id }}
          path: autotest/.failed/**

      - name: Upload benchmark result artifact
        uses: actions/upload-artifact@v4
        with:
          name: benchmarks-${{ matrix.os }}-${{ matrix.python-version }}-${{ github.run_id }}
          path: autotest/.benchmarks/*.json
          include-hidden-files: true

  post_benchmark:
    needs:
      - benchmark
    name: Process benchmark results
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash
    timeout-minutes: 10

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup uv
        uses: astral-sh/setup-uv@v5
        with:
          version: "0.5.18"

      - name: Setup Python
        uses: actions/setup-python@v5

      - name: Install Python dependencies
        run: uv pip install numpy pandas matplotlib seaborn

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: autotest/.benchmarks

      - name: Process benchmark results
        run: |
          repo="${{ github.repository }}"
          path="autotest/.benchmarks"

          # list benchmark artifacts
          artifact_json=$(gh api -X GET -H "Accept: application/vnd.github+json" /repos/$repo/actions/artifacts)

          # get artifact ids and download artifacts
          get_artifact_ids="
          import json
          import sys
          from os import linesep

          artifacts = json.load(sys.stdin, strict=False)['artifacts']
          artifacts = [a for a in artifacts if a['name'].startswith('benchmarks-') and a['name'].split('-')[-1].isdigit()]

          print(linesep.join([str(a['id']) for a in artifacts]))
          "
          echo $artifact_json \
            | python -c "$get_artifact_ids" \
            | xargs -I@ bash -c "gh api -H 'Accept: application/vnd.github+json' /repos/$repo/actions/artifacts/@/zip >> $path/@.zip"
          
          # unzip artifacts
          zipfiles=( $path/*.zip )
          if (( ${#zipfiles[@]} )); then
            unzip -o "$path/*.zip" -d $path
          fi

          # process benchmarks
          uv run python scripts/process_benchmarks.py $path $path
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmarks-${{ github.run_id }}
          path: |
            autotest/.benchmarks/*.csv
            autotest/.benchmarks/*.png
